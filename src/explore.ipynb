{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 1: Instalar la API de Kaggle\n",
    "\n",
    "pip install kaggle\n",
    "\n",
    "Paso 2: Obtener tu API Key de Kaggle\n",
    "\n",
    "En la sección \"API\", haz clic en Create New API Token. Esto descargará un archivo llamado kaggle.json.\n",
    "\n",
    "Paso 3: Configurar la API Key\n",
    "\n",
    "- En sistemas Unix/Linux/Mac:\n",
    "\n",
    "    (en bash)\n",
    "\n",
    "    mkdir ~/.kaggle\n",
    "\n",
    "    mv kaggle.json ~/.kaggle/\n",
    "\n",
    "    chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "- En Windows:\n",
    "\n",
    "    Crea la carpeta .kaggle en C:\\Users\\<tu_nombre_de_usuario>\\.\n",
    "\n",
    "    Mueve el archivo kaggle.json a esa carpeta.\n",
    "\n",
    "Paso 4: Buscar el Dataset en Kaggle\n",
    "\n",
    "Paso 5: Descargar el Dataset\n",
    "\n",
    "kaggle datasets download -d <autor>/<nombre-dataset>\n",
    "\n",
    "(Esto descargará un archivo .zip en tu directorio actual.)\n",
    "\n",
    "Paso 6: Extraer el Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas a las carpetas\n",
    "train_dir = \"../dogs-vs-cats/train\"\n",
    "\n",
    "# Filtrar nombres de archivos de perros y gatos\n",
    "dog_files = [os.path.join(train_dir, f) for f in os.listdir(train_dir) if f.startswith(\"dog\")]\n",
    "cat_files = [os.path.join(train_dir, f) for f in os.listdir(train_dir) if f.startswith(\"cat\")]\n",
    "\n",
    "# Función para cargar, redimensionar y visualizar imágenes\n",
    "def plot_images_pillow(image_paths, title, size=(200, 200)):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, img_path in enumerate(image_paths[:9]):  # Mostrar las primeras 9 imágenes\n",
    "        try:\n",
    "            img = Image.open(img_path)  # Cargar imagen\n",
    "            img = img.resize(size)  # Redimensionar\n",
    "            img = img.convert(\"RGB\")\n",
    "            plt.subplot(3, 3, i + 1)  # Crear una cuadrícula de 3x3\n",
    "            plt.imshow(img)\n",
    "            plt.axis(\"off\")    \n",
    "            plt.title(f\"Img {i+1}\", fontsize=10)        \n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la imagen {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar las primeras 9 imágenes de perros\n",
    "plot_images_pillow(dog_files, \"Perros\", size=(200, 200))\n",
    "\n",
    "# Mostrar las primeras 9 imágenes de gatos\n",
    "plot_images_pillow(cat_files, \"Gatos\", size=(200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio de datos\n",
    "train_dir = \"../dogs-vs-cats/train\"\n",
    "\n",
    "# Dimensiones de las imágenes\n",
    "img_size = (200, 200)\n",
    "\n",
    "# Inicializar listas para imágenes y etiquetas\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Cargar imágenes y asignar etiquetas\n",
    "for filename in os.listdir(train_dir):\n",
    "    label = 1 if filename.startswith(\"dog\") else 0  # 1 para perros, 0 para gatos\n",
    "    img_path = os.path.join(train_dir, filename)\n",
    "    \n",
    "    try:\n",
    "        img = load_img(img_path, target_size=img_size)  # Cargar y redimensionar\n",
    "        img_array = img_to_array(img) / 255.0  # Normalizar a rango [0, 1]\n",
    "        images.append(img_array)\n",
    "        labels.append(label)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar {filename}: {e}\")\n",
    "\n",
    "# Convertir listas a arrays de NumPy\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Mostrar información sobre los datos cargados\n",
    "print(f\"Total de imágenes cargadas: {images.shape[0]}\")\n",
    "print(f\"Dimensiones de las imágenes: {images.shape[1:]}\")  # (200, 200, 3)\n",
    "print(f\"Distribución de etiquetas: {np.unique(labels, return_counts=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cargar imágenes con load_img:\n",
    "\n",
    "    - Redimensionamos cada imagen a 200x200 píxeles directamente al cargarla.\n",
    "\n",
    "2. Convertir a arrays:\n",
    "\n",
    "    - Usamos img_to_array para convertir la imagen en un array NumPy.\n",
    "\n",
    "    - Normalizamos los valores de píxeles a [0, 1] dividiendo entre 255.\n",
    "\n",
    "3. Etiquetado:\n",
    "\n",
    "    - Los nombres de los archivos (cat y dog) determinan las etiquetas (0 o 1).\n",
    "\n",
    "4. Convertir a Arrays:\n",
    "\n",
    "    - Finalmente, convertimos las listas de imágenes y etiquetas a arrays NumPy para facilitar el procesamiento posterior.\n",
    "\n",
    "5. Resultado:\n",
    "\n",
    "    - images tiene la forma (25000, 200, 200, 3) (25,000 imágenes de 200x200 píxeles con 3 canales de color).\n",
    "\n",
    "    - labels tiene la forma (25000,) con las etiquetas correspondientes.\n",
    "\n",
    "    ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio de entrenamiento y prueba\n",
    "train_dir = \"../dogs-vs-cats/train\"\n",
    "test_dir = \"../dogs-vs-cats/test1\"\n",
    "\n",
    "# Crear un DataFrame para las imágenes de entrenamiento\n",
    "# Convertir etiquetas numéricas a strings\n",
    "train_files = os.listdir(train_dir)\n",
    "train_labels = ['dog' if 'dog' in f else 'cat' for f in train_files]\n",
    "\n",
    "# Crear DataFrame con etiquetas en formato string\n",
    "train_df = pd.DataFrame({\n",
    "    'filename': [os.path.join(train_dir, f) for f in train_files],\n",
    "    'class': train_labels\n",
    "})\n",
    "\n",
    "# Configurar el ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2  # Separar 20% de los datos para validación\n",
    ")\n",
    "\n",
    "# Generadores de datos de entrenamiento y validación\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame para las imágenes de prueba\n",
    "test_files = os.listdir(test_dir)\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': [os.path.join(test_dir, f) for f in test_files]\n",
    "})\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='filename',\n",
    "    y_col=None,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=None,  # Sin etiquetas\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: Construye una RNA\n",
    "\n",
    "Cualquier clasificador que se ajuste a este problema tendrá que ser robusto porque algunas imágenes muestran al gato o al perro en una esquina o tal vez a 2 gatos o perros en la misma foto. Si has podido investigar algunas de las implementaciones de los ganadores de otras competiciones también relacionadas con imágenes, verás que VGG16 es una arquitectura de CNN utilizada para ganar la competencia de Kaggle ILSVR (Imagenet) en 2014. Se considera una de las arquitecturas de modelos de visión con mejores resultados hasta la fecha.\n",
    "\n",
    "Utiliza la siguiente arquitectura de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo secuencial\n",
    "model = Sequential()\n",
    "\n",
    "# Bloque 1\n",
    "model.add(Conv2D(input_shape=(224, 224, 3), filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Bloque 2\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Bloque 3\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Bloque 4\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Bloque 5\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Capas completamente conectadas\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096, activation=\"relu\"))\n",
    "model.add(Dense(units=4096, activation=\"relu\"))\n",
    "\n",
    "\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))  # Capa de salida con una neurona\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=1 ,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"../models/vgg16_1.h5\", monitor = \"val_accuracy\", verbose = 1, save_best_only = True, save_weights_only = False, mode = \"auto\")\n",
    "early = EarlyStopping(monitor = \"val_accuracy\", patience = 3, verbose = 1, mode = \"auto\")\n",
    "hist = model.fit(train_generator, steps_per_epoch = 100, validation_data = test_generator, validation_steps = 10, epochs = 3, callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trazar los resultados\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history[\"val_accuracy\"])\n",
    "plt.plot(hist.history[\"loss\"])\n",
    "plt.plot(hist.history[\"val_loss\"])\n",
    "\n",
    "# Configurar el diseño del gráfico\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\", \"Loss\", \"Validation Loss\"])\n",
    "\n",
    "# Trazar\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "\n",
    "img = image.load_img(\"../dogs-vs-cats/test1/9.jpg\", target_size = (200, 200))\n",
    "img = np.asarray(img)\n",
    "plt.imshow(img)\n",
    "img = np.expand_dims(img, axis = 0)\n",
    "saved_model = load_model(\"../models/vgg16_1.h5\")\n",
    "output = saved_model.predict(img)\n",
    "if output[0][0] > output[0][1]:\n",
    "    print(\"cat\")\n",
    "else:\n",
    "    print(\"dog\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
